# Model Serving

## Links

- https://github.com/codekow/s2i-patch/tree/main/s2i-triton
- https://docs.vllm.ai/en/latest/index.html
- https://github.com/triton-inference-server/vllm_backend
- https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver/tags
- https://github.com/microsoft/DeepSpeed
- https://gitlab.consulting.redhat.com/ai-practice/awesome-ai-discovery/-/blob/master/LLMs/vLLM%20Reference%20Implementation.adoc?ref_type=heads
- https://github.com/rh-aiservices-bu/llm-on-openshift/blob/main/llm-servers/vllm/README.md
- https://github.com/redhat-na-ssa/demo-ocp-gpu/blob/main/containers/udi-cuda/ubi8/Dockerfile
- https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver/tags
- https://github.com/triton-inference-server/vllm_backend
